{"componentChunkName":"component---src-templates-docs-js","path":"/03_word_window","result":{"data":{"site":{"siteMetadata":{"title":"CS224n Natural Language Processing Tutorial | Abhishek Dutt","docsLocation":"https://abhishekdutt.github.io/cs224n-tensorflow/"}},"mdx":{"fields":{"id":"252ec017-8b55-56fc-9441-4006066399a0","title":"03. Word Window Classification, Neural Networks, and Matrix Calculus","slug":"/03_word_window"},"body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"03. Word Window Classification, Neural Networks, and Matrix Calculus\",\n  \"metaTitle\": \"This is the title tag of this page\",\n  \"metaDescription\": \"This is the meta description\"\n};\n\nvar makeShortcode = function makeShortcode(name) {\n  return function MDXDefaultShortcode(props) {\n    console.warn(\"Component \" + name + \" was not imported, exported, or provided by MDXProvider as global scope\");\n    return mdx(\"div\", props);\n  };\n};\n\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", null, \"Classification:\"), mdx(\"p\", null, \"Generally heres what a \"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"x\\u1D62 = \\u23A1 \\u23A4\\n     \\u23A2 \\u23A5\\n     \\u23A3 \\u23A6\\n\")), mdx(\"button\", null, \"Edit my text\"), mdx(\"p\", null, \"start testing latex \"), mdx(\"p\", null, mdx(\"span\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"katex\"\n  }), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"katex-mathml\"\n  }), mdx(\"math\", _extends({\n    parentName: \"span\"\n  }, {\n    \"xmlns\": \"http://www.w3.org/1998/Math/MathML\"\n  }), mdx(\"semantics\", {\n    parentName: \"math\"\n  }, mdx(\"mrow\", {\n    parentName: \"semantics\"\n  }, mdx(\"msup\", {\n    parentName: \"mrow\"\n  }, mdx(\"mi\", {\n    parentName: \"msup\"\n  }, \"a\"), mdx(\"mn\", {\n    parentName: \"msup\"\n  }, \"2\")), mdx(\"mo\", {\n    parentName: \"mrow\"\n  }, \"+\"), mdx(\"msup\", {\n    parentName: \"mrow\"\n  }, mdx(\"mi\", {\n    parentName: \"msup\"\n  }, \"b\"), mdx(\"mn\", {\n    parentName: \"msup\"\n  }, \"2\")), mdx(\"mo\", {\n    parentName: \"mrow\"\n  }, \"=\"), mdx(\"msup\", {\n    parentName: \"mrow\"\n  }, mdx(\"mi\", {\n    parentName: \"msup\"\n  }, \"c\"), mdx(\"mn\", {\n    parentName: \"msup\"\n  }, \"2\"))), mdx(\"annotation\", _extends({\n    parentName: \"semantics\"\n  }, {\n    \"encoding\": \"application/x-tex\"\n  }), \"a^2 + b^2 = c^2\")))), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"katex-html\",\n    \"aria-hidden\": \"true\"\n  }), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"base\"\n  }), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"strut\",\n    \"style\": {\n      \"height\": \"0.897438em\",\n      \"verticalAlign\": \"-0.08333em\"\n    }\n  })), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"mord\"\n  }), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"mord mathdefault\"\n  }), \"a\"), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"msupsub\"\n  }), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"vlist-t\"\n  }), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"vlist-r\"\n  }), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"vlist\",\n    \"style\": {\n      \"height\": \"0.8141079999999999em\"\n    }\n  }), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"style\": {\n      \"top\": \"-3.063em\",\n      \"marginRight\": \"0.05em\"\n    }\n  }), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"pstrut\",\n    \"style\": {\n      \"height\": \"2.7em\"\n    }\n  })), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"sizing reset-size6 size3 mtight\"\n  }), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"mord mtight\"\n  }), \"2\")))))))), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"mspace\",\n    \"style\": {\n      \"marginRight\": \"0.2222222222222222em\"\n    }\n  })), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"mbin\"\n  }), \"+\"), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"mspace\",\n    \"style\": {\n      \"marginRight\": \"0.2222222222222222em\"\n    }\n  }))), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"base\"\n  }), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"strut\",\n    \"style\": {\n      \"height\": \"0.8141079999999999em\",\n      \"verticalAlign\": \"0em\"\n    }\n  })), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"mord\"\n  }), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"mord mathdefault\"\n  }), \"b\"), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"msupsub\"\n  }), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"vlist-t\"\n  }), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"vlist-r\"\n  }), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"vlist\",\n    \"style\": {\n      \"height\": \"0.8141079999999999em\"\n    }\n  }), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"style\": {\n      \"top\": \"-3.063em\",\n      \"marginRight\": \"0.05em\"\n    }\n  }), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"pstrut\",\n    \"style\": {\n      \"height\": \"2.7em\"\n    }\n  })), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"sizing reset-size6 size3 mtight\"\n  }), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"mord mtight\"\n  }), \"2\")))))))), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"mspace\",\n    \"style\": {\n      \"marginRight\": \"0.2777777777777778em\"\n    }\n  })), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"mrel\"\n  }), \"=\"), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"mspace\",\n    \"style\": {\n      \"marginRight\": \"0.2777777777777778em\"\n    }\n  }))), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"base\"\n  }), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"strut\",\n    \"style\": {\n      \"height\": \"0.8141079999999999em\",\n      \"verticalAlign\": \"0em\"\n    }\n  })), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"mord\"\n  }), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"mord mathdefault\"\n  }), \"c\"), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"msupsub\"\n  }), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"vlist-t\"\n  }), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"vlist-r\"\n  }), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"vlist\",\n    \"style\": {\n      \"height\": \"0.8141079999999999em\"\n    }\n  }), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"style\": {\n      \"top\": \"-3.063em\",\n      \"marginRight\": \"0.05em\"\n    }\n  }), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"pstrut\",\n    \"style\": {\n      \"height\": \"2.7em\"\n    }\n  })), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"sizing reset-size6 size3 mtight\"\n  }), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"mord mtight\"\n  }), \"2\")))))))))))), mdx(\"p\", null, \"test again\"), mdx(\"span\", {\n    \"className\": \"katex-display\"\n  }, mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"katex\"\n  }), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"katex-mathml\"\n  }), mdx(\"math\", _extends({\n    parentName: \"span\"\n  }, {\n    \"xmlns\": \"http://www.w3.org/1998/Math/MathML\"\n  }), mdx(\"semantics\", {\n    parentName: \"math\"\n  }, mdx(\"mrow\", {\n    parentName: \"semantics\"\n  }, mdx(\"msup\", {\n    parentName: \"mrow\"\n  }, mdx(\"mi\", {\n    parentName: \"msup\"\n  }, \"a\"), mdx(\"mn\", {\n    parentName: \"msup\"\n  }, \"2\")), mdx(\"mo\", {\n    parentName: \"mrow\"\n  }, \"+\"), mdx(\"msup\", {\n    parentName: \"mrow\"\n  }, mdx(\"mi\", {\n    parentName: \"msup\"\n  }, \"b\"), mdx(\"mn\", {\n    parentName: \"msup\"\n  }, \"2\")), mdx(\"mo\", {\n    parentName: \"mrow\"\n  }, \"=\"), mdx(\"msup\", {\n    parentName: \"mrow\"\n  }, mdx(\"mi\", {\n    parentName: \"msup\"\n  }, \"c\"), mdx(\"mn\", {\n    parentName: \"msup\"\n  }, \"2\"))), mdx(\"annotation\", _extends({\n    parentName: \"semantics\"\n  }, {\n    \"encoding\": \"application/x-tex\"\n  }), \"a^2 + b^2 = c^2\")))), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"katex-html\",\n    \"aria-hidden\": \"true\"\n  }), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"base\"\n  }), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"strut\",\n    \"style\": {\n      \"height\": \"0.9474379999999999em\",\n      \"verticalAlign\": \"-0.08333em\"\n    }\n  })), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"mord\"\n  }), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"mord mathdefault\"\n  }), \"a\"), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"msupsub\"\n  }), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"vlist-t\"\n  }), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"vlist-r\"\n  }), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"vlist\",\n    \"style\": {\n      \"height\": \"0.8641079999999999em\"\n    }\n  }), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"style\": {\n      \"top\": \"-3.113em\",\n      \"marginRight\": \"0.05em\"\n    }\n  }), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"pstrut\",\n    \"style\": {\n      \"height\": \"2.7em\"\n    }\n  })), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"sizing reset-size6 size3 mtight\"\n  }), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"mord mtight\"\n  }), \"2\")))))))), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"mspace\",\n    \"style\": {\n      \"marginRight\": \"0.2222222222222222em\"\n    }\n  })), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"mbin\"\n  }), \"+\"), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"mspace\",\n    \"style\": {\n      \"marginRight\": \"0.2222222222222222em\"\n    }\n  }))), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"base\"\n  }), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"strut\",\n    \"style\": {\n      \"height\": \"0.8641079999999999em\",\n      \"verticalAlign\": \"0em\"\n    }\n  })), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"mord\"\n  }), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"mord mathdefault\"\n  }), \"b\"), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"msupsub\"\n  }), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"vlist-t\"\n  }), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"vlist-r\"\n  }), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"vlist\",\n    \"style\": {\n      \"height\": \"0.8641079999999999em\"\n    }\n  }), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"style\": {\n      \"top\": \"-3.113em\",\n      \"marginRight\": \"0.05em\"\n    }\n  }), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"pstrut\",\n    \"style\": {\n      \"height\": \"2.7em\"\n    }\n  })), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"sizing reset-size6 size3 mtight\"\n  }), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"mord mtight\"\n  }), \"2\")))))))), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"mspace\",\n    \"style\": {\n      \"marginRight\": \"0.2777777777777778em\"\n    }\n  })), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"mrel\"\n  }), \"=\"), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"mspace\",\n    \"style\": {\n      \"marginRight\": \"0.2777777777777778em\"\n    }\n  }))), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"base\"\n  }), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"strut\",\n    \"style\": {\n      \"height\": \"0.8641079999999999em\",\n      \"verticalAlign\": \"0em\"\n    }\n  })), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"mord\"\n  }), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"mord mathdefault\"\n  }), \"c\"), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"msupsub\"\n  }), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"vlist-t\"\n  }), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"vlist-r\"\n  }), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"vlist\",\n    \"style\": {\n      \"height\": \"0.8641079999999999em\"\n    }\n  }), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"style\": {\n      \"top\": \"-3.113em\",\n      \"marginRight\": \"0.05em\"\n    }\n  }), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"pstrut\",\n    \"style\": {\n      \"height\": \"2.7em\"\n    }\n  })), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"sizing reset-size6 size3 mtight\"\n  }), mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"mord mtight\"\n  }), \"2\")))))))))))), mdx(\"p\", null, \"end test latex\"), mdx(\"p\", null, \"Aim of this section:\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Softmax function (and not the softmax classifier)\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Cross entropy Loss\")), mdx(\"h1\", null, \"Softmax and cross entropy\"), mdx(\"p\", null, \"The famous 2 class binary classifier is represented like this:\\nlogit(p)=ln(p/1-p)=w1x1+w2x2+w3x3+c\\n<-- ???\"), mdx(\"p\", null, \"This section is an excuse to explain softmax, cross entropy loss:\\nFor this discussion we are trying to classify d dim input vector into C classes.\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"  \\uD835\\uDC65                                       \\uD835\\uDC66\\u0302\\n\\u23A1 x1 \\u23A4                                  \\u23A1 y1 \\u23A4\\n\\u23A2 x2 \\u23A5       \\u250C\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510       \\u23A2 y2 \\u23A5\\n\\u23A2 x3 \\u23A5 \\u2012\\u2012\\u2012\\u2012\\u227B \\u2502 Classifier Model \\u2502 \\u2012\\u2012\\u2012\\u2012\\u227B \\u23A2 y3 \\u23A5\\n\\u23A2 \\xB7  \\u23A5       \\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518       \\u23A2 \\xB7  \\u23A5\\n\\u23A2 \\xB7  \\u23A5                                  \\u23A2 \\xB7  \\u23A5\\n\\u23A3 xd \\u23A6                                  \\u23A3 yc \\u23A6\\n\\n\")), mdx(\"p\", null, \"As a black box, a classifier model takes an :\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"input vector \", mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"\\uD835\\uDC65\\u1D62\"), \" (lets say of dimesnion d) \"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"and gives an output vector \\uD835\\uDC66\\u0302\\u1D62 (of dimension equalling number of classes).\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Here each row in the \\uD835\\uDC66\\u0302 gives a probability of \\uD835\\uDC65 belonging to that class 1, 2, ..., c etc. \"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"We simply take x to be belonging to the class which has the highest probablity (in above example it x_i would belong to class 2).\")), mdx(\"p\", null, \"A softmax classifier (called so becauses it uses softmax function), \\uD835\\uDC66\\u0302 by a simple matrix multiplication.\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"  \\uD835\\uDC65                                                 \\uD835\\uDC66\\u0302\\n\\u23A1 \\uD835\\uDC65\\u2081 \\u23A4\\n\\u23A2 \\uD835\\uDC65\\u2082 \\u23A5                                            \\u23A1 \\uD835\\uDC66\\u0302\\u2081 \\u23A4\\n\\u23A2 \\uD835\\uDC65\\u2083 \\u23A5 \\u2012\\u2012\\u2012\\u2012\\u227B Wx \\u2012\\u2012\\u2012\\u2012\\u227B exp() \\u2012\\u2012\\u2012\\u2012\\u227B Softmax() \\u2012\\u2012\\u2012\\u2012\\u227B \\u23A2 \\uD835\\uDC66\\u0302\\u2082 \\u23A5\\n\\u23A2 \\u22EE  \\u23A5                                            \\u23A2 \\u22EE   \\u23A2\\n\\u23A3 \\uD835\\uDC65d \\u23A6                                            \\u23A3 \\uD835\\uDC66\\u0302c \\u23A6\\n\\n\")), mdx(\"p\", null, \"Weight matrix W has dimensions (C,d) i.e. rows = no. of classes and columns = dimension of input vector\\nValues of matrix W are determined by training the model on input x_i's for whome we know the correct class y_i's, and compare the model's output yHat_i with y_i's and adjusting values of the matrix W.\"), mdx(\"p\", null, \"So at the start of the training we don't know the matrix W so I have arbitrarily chosen it to be all 0s (in practice there are more intelligent ways to initalize, such as Xaver's initalization for e.g.)\"), mdx(\"h3\", null, \"Step 1:\"), mdx(\"p\", null, \"for (training or prediction both) we calculate the dot product W.x. This will give a vector dim (C, 1). \", mdx(\"br\", null), \"\\nIf \\uD835\\uDC53\\u1D67 is the yth element of W.x then: \", mdx(\"br\", null)), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"\\uD835\\uDC53\\u1D67 \\u2550 \\uD835\\uDC4A\\u1D67\\xB7\\uD835\\uDC65 \\u2550 \\u2211\\uD835\\uDC4A\\u1D67\\u1D62\\xB7\\uD835\\uDC65\\u1D62\\n\\nWhere \\uD835\\uDC4A\\u1D67 = yth row of W\\nand \\uD835\\uDC4A\\u1D67\\u1D62 = (y,i) element of W\\n\")), mdx(\"p\", null, \"Each \\uD835\\uDC53\\u1D67 gives a score how much the model thinks x belongs to the yth class.\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"      \\u23A1 w11 w12 \\xB7 w1d \\u23A4 \\u23A1 x1 \\u23A4   \\u23A1 w11\\xB7x1\\uFF0Bw12\\xB7x2\\uFF0B\\u22EF\\uFF0Bw1d\\xB7xd \\u23A4\\n      \\u23A2 w21 w22 \\xB7 w2d \\u23A5 \\u23A2 x2 \\u23A5   \\u23A2 w21\\xB7x1\\uFF0Bw22\\xB7x2\\uFF0B\\u22EF\\uFF0Bw2d\\xB7xd \\u23A5\\nW\\xB7x \\u2550 \\u23A2  \\xB7   \\xB7  \\xB7  \\xB7  \\u23A5 \\u23A2 x3 \\u23A5   \\u23A2    \\xB7       \\xB7         \\xB7   \\u23A5\\n      \\u23A2 wy1 wy2 \\xB7 wyd \\u23A5\\xB7\\u23A2 \\xB7  \\u23A5 \\u2550 \\u23A2    \\xB7       \\xB7         \\xB7   \\u23A5\\n      \\u23A2  \\xB7   \\xB7  \\xB7  \\xB7  \\u23A5 \\u23A2 \\xB7  \\u23A5   \\u23A2 wy1\\xB7x1\\uFF0Bwy2\\xB7x2\\uFF0B\\u22EF\\uFF0Bwyd\\xB7xd \\u23A5\\n      \\u23A3 wc1 wc2 \\xB7 wcd \\u23A6 \\u23A2 \\xB7  \\u23A5   \\u23A2    \\xB7       \\xB7         \\xB7   \\u23A5\\n                        \\u23A3 xd \\u23A6   \\u23A3 wc1\\xB7x1\\uFF0Bwc2\\xB7x2\\uFF0B\\u22EF\\uFF0Bwcd\\xB7xd \\u23A6\\n\\n      \\u23A1 \\u03A3 w1j\\xB7xi \\u23A4   \\u23A1 f1 \\u23A4\\n      \\u23A2 \\u03A3 w2j\\xB7xi \\u23A5   \\u23A2 f2 \\u23A5\\n      \\u23A2      \\xB7   \\u23A5   \\u23A2 \\xB7  \\u23A5\\n    \\u2550 \\u23A2      \\xB7   \\u23A5 \\u2550 \\u23A2 \\xB7  \\u23A5 \\n      \\u23A2 \\u03A3 wyj\\xB7xi \\u23A5   \\u23A2 fy \\u23A5\\n      \\u23A2      \\xB7   \\u23A5   \\u23A2 \\xB7  \\u23A5\\n      \\u23A3 \\u03A3 wcj\\xB7xi \\u23A6   \\u23A3 fc \\u23A6\\n\")), mdx(\"h3\", null, \"Step 2:\"), mdx(\"p\", null, \"Value in each row 1, 2, 3 gives a score which tells how strongly the classifier thinks the input vector x_i belongs to class 1, 2, 3. In this example classifier thinks x_i belongs to class 1, 2, 3 in those order.\\nBut these scores are not probablilites (e.g. they may be greater than 1 or less than zero. Also all 3 dont add up to 1 (coz x_i must belong to one of the 3 classes)). Now to convert these scores into probabiliites we apply a softmax function.\"), mdx(\"p\", null, \"Softmax operator takes a vector of numbers and normalizes them into a probabalities that add up to one.\\ne.g. Lets say we built classification model (e.g. the logistic one described above) which outputs a score f_y for our input vector xi.\\nEach row represents the probabablity of the input x_i belonging to class 0 or 1 or 2.\"), mdx(\"p\", null, \"After softmax operation yHat_i = softmax(f_y) = exp(f_y) / Sigma exp(f_c).\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"Softmax(fy) = exp(fy)/ \\u03A3 exp(fc)\\n\")), mdx(\"p\", null, \"Applying element wise softmax to the vector W.x we get probababilites of x belonging to each class.\\ne.g. probability of x belonging to class y: \", mdx(\"br\", null)), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"p(y|x) = softmax(fy) = exp(fy)/ \\u03A3 exp(fc) = exp(\\u2211\\uD835\\uDC4A\\u1D67\\xB7\\uD835\\uDC65)/ \\u03A3 exp(\\u2211\\uD835\\uDC4A\\uA700\\xB7\\uD835\\uDC65)\\n\\nApplied to whole W.x:\\n\\n    \\u23A1 softmax(f1) \\u23A4   \\u23A1 p(Y=1|x) \\u23A4\\n    \\u23A2 softmax(f2) \\u23A5   \\u23A2 p(Y=2|x) \\u23A5\\n\\uD835\\uDC66\\u0302 \\u2550 \\u23A2      .      \\u23A5 \\u2550 \\u23A2 .        \\u23A5\\n    \\u23A2      .      \\u23A5   \\u23A2 .        \\u23A5\\n    \\u23A3 softmax(fc) \\u23A6   \\u23A3 p(Y=c|x) \\u23A6\\n\")), mdx(\"p\", null, \"Visually if f = W_y.x = \", \"[ f_1, f_2, ..., f_y, ...]\", \"^T\\nyHat_i = softmax(f)\\nyHat_i = \", \"[exp(f_1) / Sigma exp(f_c), exp(f_2) / Sigma exp(f_c), ..., exp(f_y) / Sigma exp(f_c), ...]\", \"^T\\nyHat_i = 1/(Sigma exp(f_c)) * \", \"[exp(f_1), exp(f_1), ..., exp(f_1), ..]\", \" ^T\\nOk so we have probablities of x_i belonging to each class.\\nNow a good classifer model we should give highest probablity to the correct class that x_i belongs to.\\nAnd also do so for any input x that we give it in future. (or atleast as try to be as good as it can)\"), mdx(\"h3\", null, \"Step 3:\"), mdx(\"p\", null, \"Now how good or bad our model performs depends on the weight matrix.\\nWe need to set the values in the weight matrix such that it the model gives highest probababilites to the correct class for each input x.\\nFOr this we need training data, i.e. x's for which we know the correct class y.\\nSo we can compare the model's probabilites with correct class and adjust weight matrix accordingly.\\nThis is done by loss function. One of them is Cross entropy loss.\\nFor one input x, it is defined as H(p, q) { - SUM true probability * log(predicted probability) } (Summation over class 1..c)\\nPredicted probability is yHat we get from the model.\\nTrue probability is a one hot vector p=\", \"[0,0,0..,1,..0]\", \"  (since we already know the correct class for each training input x.)\\nTherefore H(p,q) = -log(q) {Here q is the prob corresponding to the correct class of x}\\nThis H(p, q) is for one example x. To calculate loss for whole training set we average H(p, q) for all x's belonging to training set.\\nJ(0) = -1/N(SUM -log(q)) = -1/N(SUM -log(exp(fy)/ \\u03A3 exp(fc)))\"), mdx(\"p\", null, \"A small example of the same with numbers.\\nLets say we have a 3 dimension input we want to classify into 3 classes (i.e. d=3, C=3):\\nx_i = \", \"[1, 2, 3]\", \" \"), mdx(\"p\", null, \"W=[\", \"[1 , 2, 3][1, 2, 3]\", \"[1, 2, 3]\", \"]\\nf = W_y.x = \", \"[1, 2, 3]\", \" = \", \"[f_1, f_2, f_3]\", \" = \", \"[Sigma W_1i \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \" xi, Sigma W_2i \"), \" xi, Sigma W_3i * xi]\", \" = \", \"[W_1.x, W_2.x, W_3.x]\", \"\\nValue in each row 1, 2, 3 gives a score which tells how strongly the classifier thinks the input vector x_i belongs to class 1, 2, 3. In this example classifier thinks x_i belongs to class 1, 2, 3 in those order.\\nBut these scores are not probablilites (e.g. they may be greater than 1 or less than zero. Also all 3 dont add up to 1 (coz x_i must belong to one of the 3 classes)). Now to convert these scores into probabiliites we apply a softmax function.\"), mdx(\"p\", null, \"yHat_i = Softmax(f) = \", \"[p(y=1|x_i), p(y=2|x_i), p(y=3|x_i)]\", \" = \"), mdx(\"p\", null, \"(We dont know the values w_ij of W matrix, whole point of building a classification model is to find the matrix W which gives good estimates yHat_i for any given input x_i)\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \" \\uD835\\uDC65\\u1D62                                   \\uD835\\uDC66\\u0302\\u1D62\\n\\u23A11\\u23A4\\n\\u23A22\\u23A5       \\u250C\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510       \\u23A11\\u23A4\\n\\u23A23\\u23A5 \\u2012\\u2012\\u2012\\u2012\\u227B \\u2502 Classifier Model \\u2502 \\u2012\\u2012\\u2012\\u2012\\u227B \\u23A22\\u23A5\\n\\u23A24\\u23A5       \\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518       \\u23A33\\u23A6\\n\\u23A35\\u23A6\\n \\n\\n \\uD835\\uDC65\\u1D62                 Softmax(\\uD835\\uDC4A\\xB7\\uD835\\uDC65\\u1D62)           \\uD835\\uDC66\\u0302\\u1D62\\n\\n\\u23A11\\u23A4               \\u239B             \\u23A11\\u23A4 \\u239E\\n\\u23A22\\u23A5               \\u239C \\u23A11 2 3 4 5\\u23A4 \\u23A22\\u23A5 \\u239F       \\u23A11\\u23A4\\n\\u23A23\\u23A5 \\u2012\\u2012\\u2012\\u2012\\u227B  Softmax\\u239C \\u23A21 2 3 4 5\\u23A5\\xB7\\u23A23\\u23A5 \\u239F \\u2012\\u2012\\u2012\\u2012\\u227B \\u23A22\\u23A5\\n\\u23A24\\u23A5               \\u239C \\u23A31 2 3 4 5\\u23A6 \\u23A24\\u23A5 \\u239F       \\u23A33\\u23A6\\n\\u23A35\\u23A6               \\u239D             \\u23A35\\u23A6 \\u23A0\\n \\n\\n\\u23A11\\u23A4\\n\\u23A22\\u23A5                      \\u239B \\u23A11\\u23A4 \\u239E            \\u23A11\\u23A4\\n\\u23A23\\u23A5   \\u2012\\u2012\\u2012\\u2012\\u227B       Softmax\\u239C \\u23A22\\u23A5 \\u239F    \\u2012\\u2012\\u2012\\u2012\\u227B   \\u23A22\\u23A5\\n\\u23A24\\u23A5                      \\u239D \\u23A33\\u23A6 \\u23A0            \\u23A33\\u23A6\\n\\u23A35\\u23A6\\n\\n               \\u23A1 \\u239B       \\u212F(1)         \\u239E \\u23A4\\n               \\u23A2 \\u239C \\u2012\\u2012\\u2012\\u2012\\u2012\\u2012\\u2012\\u2012\\u2012\\u2012\\u2012\\u2012\\u2012\\u2012\\u2012\\u2012\\u2012\\u2012 \\u239F \\u23A5\\n               \\u23A2 \\u239D \\u212F(1) + \\u212F(2) + \\u212F(3) \\u23A0 \\u23A5\\n\\u23A11\\u23A4            \\u23A2                        \\u23A5\\n\\u23A22\\u23A5            \\u23A2 \\u239B       \\u212F(2)         \\u239E \\u23A5         \\u23A11\\u23A4\\n\\u23A23\\u23A5   \\u2012\\u2012\\u2012\\u2012\\u227B    \\u23A2 \\u239C \\u2012\\u2012\\u2012\\u2012\\u2012\\u2012\\u2012\\u2012\\u2012\\u2012\\u2012\\u2012\\u2012\\u2012\\u2012\\u2012\\u2012\\u2012 \\u239F \\u23A5  \\u2012\\u2012\\u2012\\u2012\\u227B  \\u23A22\\u23A5\\n\\u23A24\\u23A5            \\u23A2 \\u239D \\u212F(1) + \\u212F(2) + \\u212F(3) \\u23A0 \\u23A5         \\u23A33\\u23A6\\n\\u23A35\\u23A6            \\u23A2                        \\u23A5\\n               \\u23A2 \\u239B       \\u212F(3)         \\u239E \\u23A5\\n               \\u23A2 \\u239C \\u2012\\u2012\\u2012\\u2012\\u2012\\u2012\\u2012\\u2012\\u2012\\u2012\\u2012\\u2012\\u2012\\u2012\\u2012\\u2012\\u2012\\u2012 \\u239F \\u23A5\\n               \\u23A3 \\u239D \\u212F(1) + \\u212F(2) + \\u212F(3) \\u23A0 \\u23A6 \\n\\n\")));\n}\n;\nMDXContent.isMDXComponent = true;","tableOfContents":{"items":[{"url":"#classification","title":"Classification:"},{"url":"#softmax-and-cross-entropy","title":"Softmax and cross entropy","items":[{"items":[{"url":"#step-1","title":"Step 1:"},{"url":"#step-2","title":"Step 2:"},{"url":"#step-3","title":"Step 3:"}]}]}]},"parent":{"__typename":"File","relativePath":"03_word_window.md"},"frontmatter":{"metaTitle":"This is the title tag of this page","metaDescription":"This is the meta description"}},"allMdx":{"edges":[{"node":{"fields":{"slug":"/extra_stuff","title":"Extra Stuff"}}},{"node":{"fields":{"slug":"/06_language_models_rnn","title":"06. The probability of a sentence? Recurrent Neural Networks and Language Models"}}},{"node":{"fields":{"slug":"/03_word_window","title":"03. Word Window Classification, Neural Networks, and Matrix Calculus"}}},{"node":{"fields":{"slug":"/01_word_vectors","title":"1. Word Vectors"}}},{"node":{"fields":{"slug":"/05_linguistic_structure_dependency_parsing","title":"05. Linguistic Structure: Dependency Parsing"}}},{"node":{"fields":{"slug":"/07_vanishing_gradients_fancy_rnn","title":"07. Vanishing Gradients and Fancy RNNs"}}},{"node":{"fields":{"slug":"/codeblock","title":"Syntax Highlighting"}}},{"node":{"fields":{"slug":"/15_natural_language_generation","title":"15. Natural Language Generation"}}},{"node":{"fields":{"slug":"/","title":"Welcome"}}},{"node":{"fields":{"slug":"/introduction","title":"Introduction"}}},{"node":{"fields":{"slug":"/codeblock/1-index","title":"Sub Page"}}}]}},"pageContext":{"id":"252ec017-8b55-56fc-9441-4006066399a0"}}}