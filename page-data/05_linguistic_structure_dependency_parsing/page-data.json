{"componentChunkName":"component---src-templates-docs-js","path":"/05_linguistic_structure_dependency_parsing","result":{"data":{"site":{"siteMetadata":{"title":"CS224n Natural Language Processing Tutorial | Abhishek Dutt","docsLocation":"https://abhishekdutt.github.io/cs224n-tensorflow/"}},"mdx":{"fields":{"id":"d7ecb29c-1840-5e3d-a6fe-0689c791c823","title":"05. Linguistic Structure: Dependency Parsing","slug":"/05_linguistic_structure_dependency_parsing"},"body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"05. Linguistic Structure: Dependency Parsing\",\n  \"metaTitle\": \"This is the title tag of this page\",\n  \"metaDescription\": \"This is the meta description\"\n};\n\nvar makeShortcode = function makeShortcode(name) {\n  return function MDXDefaultShortcode(props) {\n    console.warn(\"Component \" + name + \" was not imported, exported, or provided by MDXProvider as global scope\");\n    return mdx(\"div\", props);\n  };\n};\n\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", null, \"Lecture plan: Dependency parsing\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Syntactic Structure: Consistency and Dependency (25 mins)\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Dependency Grammar and Treebanks (15 mins)\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Transition-based dependency parsing (15 mins)\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Neural dependency parsing (15 mins)\")), mdx(\"p\", null, \"In this lecture, two views of linguistic structures were discussed.\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Constituency = phrase structure grammar = context-free grammars (CFGs): organizes words into nested constituents.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Dependency structure: Dependency structure shows which words depend on (modify or are arguments of) which other words.\")), mdx(\"h1\", null, \"Why do we need sentence structure?\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"We need to understand sentence structure in order to be able to interpret language correctly\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Humans communicate complex ideas by composing words together into bigger units to convey complex meanings\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"We need to know what is connected to what\")), mdx(\"h1\", null, \"Methods of Dependency Parsing\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Dynamic programming: Eisner (1996) gives a clever algorithm with complexity O(n3), by producing parse items with heads at the ends rather than in the middle\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Graph algorithms: You create a Minimum Spanning Tree for a sentence. McDonald et al.\\u2019s (2005) MSTParser scores dependencies independently using an ML classifier (he uses MIRA, for online learning, but it can be something else)\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Constraint Satisfaction: Edges are eliminated that don\\u2019t satisfy hard constraints. Karlsson (1990), etc.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"\\u201CTransition-based parsing\\u201D or \\u201Cdeterministic dependency parsing\\u201D: Greedy choice of attachments guided by good machine learning classifiers MaltParser (Nivre et al. 2008). Has proven highly effective.\")));\n}\n;\nMDXContent.isMDXComponent = true;","tableOfContents":{"items":[{"url":"#lecture-plan-dependency-parsing","title":"Lecture plan: Dependency parsing"},{"url":"#why-do-we-need-sentence-structure","title":"Why do we need sentence structure?"},{"url":"#methods-of-dependency-parsing","title":"Methods of Dependency Parsing"}]},"parent":{"__typename":"File","relativePath":"05_linguistic_structure_dependency_parsing.md"},"frontmatter":{"metaTitle":"This is the title tag of this page","metaDescription":"This is the meta description"}},"allMdx":{"edges":[{"node":{"fields":{"slug":"/03_word_window","title":"03. Word Window Classification, Neural Networks, and Matrix Calculus"}}},{"node":{"fields":{"slug":"/00_toc","title":"Introduction"}}},{"node":{"fields":{"slug":"/codeblock","title":"Syntax Highlighting"}}},{"node":{"fields":{"slug":"/01_word_vectors","title":"Word Vectors"}}},{"node":{"fields":{"slug":"/05_linguistic_structure_dependency_parsing","title":"05. Linguistic Structure: Dependency Parsing"}}},{"node":{"fields":{"slug":"/15_natural_language_generation","title":"15. Natural Language Generation"}}},{"node":{"fields":{"slug":"/07_vanishing_gradients_fancy_rnn","title":"07. Vanishing Gradients and Fancy RNNs"}}},{"node":{"fields":{"slug":"/extra_stuff","title":"Extra Stuff"}}},{"node":{"fields":{"slug":"/06_language_models_rnn","title":"06. The probability of a sentence? Recurrent Neural Networks and Language Models"}}},{"node":{"fields":{"slug":"/","title":"Welcome"}}},{"node":{"fields":{"slug":"/codeblock/1-index","title":"Sub Page"}}},{"node":{"fields":{"slug":"/01_word_vectors/01_count_based","title":"Count Based Word Vectors"}}}]}},"pageContext":{"id":"d7ecb29c-1840-5e3d-a6fe-0689c791c823"}}}