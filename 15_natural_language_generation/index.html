<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><meta property="twitter:card" content="summary_large_image"/><noscript></noscript><meta name="generator" content="Gatsby 2.18.10"/><link rel="sitemap" type="application/xml" href="/cs224n-tensorflow/sitemap.xml"/><title data-react-helmet="true">This is the title tag of this page 15</title><link data-react-helmet="true" rel="canonical" href="https://abhishekdutt.github.io/cs224n-tensorflow/15_natural_language_generation"/><meta data-react-helmet="true" name="title" content="This is the title tag of this page 15"/><meta data-react-helmet="true" name="description" content="This is the meta description"/><meta data-react-helmet="true" property="og:title" content="This is the title tag of this page 15"/><meta data-react-helmet="true" property="og:description" content="This is the meta description"/><meta data-react-helmet="true" property="twitter:title" content="This is the title tag of this page 15"/><meta data-react-helmet="true" property="twitter:description" content="This is the meta description"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-PGYTQE1RBF"></script><script>
    window.GATSBY_GTAG_PLUGIN_GA_TRACKING_ID = (
      'G-PGYTQE1RBF'
    );
    window.GATSBY_GTAG_PLUGIN_ANONYMIZE = false;

    var options = {
      send_page_view: false
    };
    if (false) {
      options.anonymize_ip = true;
    }

    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    window.gtag = gtag;
    gtag('js', new Date());
    gtag('config', 'G-PGYTQE1RBF', options);
  </script><link as="script" rel="preload" href="/cs224n-tensorflow/webpack-runtime-2f446e3feebf622e1bcb.js"/><link as="script" rel="preload" href="/cs224n-tensorflow/commons-926e13980b7ff3c9526c.js"/><link as="script" rel="preload" href="/cs224n-tensorflow/app-427e7e4f4c0d4bff0465.js"/><link as="fetch" rel="preload" href="/cs224n-tensorflow/page-data/15_natural_language_generation/page-data.json" crossorigin="anonymous"/></head><body><div id="___gatsby"><div style="outline:none" tabindex="-1" role="group" id="gatsby-focus-wrapper"><div><style data-emotion-css="0"></style><div class="navBarWrapper"><nav class="navBarDefault"><div class="navBarHeader"><a href="https://github.com/AbhishekDutt/cs224n-tensorflow" class="navBarBrand"><img class="img-responsive displayInline" src="https://graphql-engine-cdn.hasura.io/learn-hasura/assets/homepage/brand.svg" alt="logo"/></a><div class="headerTitle displayInline"><a href='https://github.com/AbhishekDutt/cs224n-tensorflow'>CS224n Tensorflow</a></div></div><div id="navbar" class="topnav"><div class="visibleMobile"><style data-emotion-css="8uxxw2">.css-8uxxw2{width:100%;height:100vh;overflow:auto;position:fixed;padding-left:0px;position:-webkit-sticky;position:-moz-sticky;position:-webkit-sticky;position:sticky;top:0;padding-right:0;-webkit-box-shadow:-1px 0px 4px 1px rgba(175,158,232,0.4);}@media only screen and (max-width:1023px){.css-8uxxw2{width:100%;height:100vh;}}@media (min-width:767px) and (max-width:1023px){.css-8uxxw2{padding-left:0;}}@media only screen and (max-width:767px){.css-8uxxw2{padding-left:0px;height:auto;}}</style><aside class="css-8uxxw2 e1sbq3r11"><ul class="sideBarUL"><li class="hideFrontLine firstLevel item "><ul><li class=" item "><a href="/cs224n-tensorflow/">Welcome</a></li><li class=" item "><a href="/cs224n-tensorflow/01_word_vectors">1. Word Vectors</a></li><li class=" item "><a href="/cs224n-tensorflow/05_linguistic_structure_dependency_parsing">05. Linguistic Structure: Dependency Parsing</a></li><li class=" item "><a aria-current="page" class="" href="/cs224n-tensorflow/15_natural_language_generation">15. Natural Language Generation</a></li><li class=" item "><a href="/cs224n-tensorflow/introduction">Introduction</a></li><li class=" item "><a href="/cs224n-tensorflow/codeblock">Syntax Highlighting<button aria-label="collapse" class="collapser"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24"><path d="M7.33 24l-2.83-2.829 9.339-9.175-9.339-9.167 2.83-2.829 12.17 11.996z"></path></svg></button></a></li></ul></li></ul></aside><hr/></div><ul class="navBarUL navBarNav navBarULRight"><li class="divider hiddenMobile"></li><li class="githubBtn"><span><a href="https://github.com/AbhishekDutt/cs224n-tensorflow" data-show-count="true" aria-label="Star on GitHub">Star</a></span></li><li><style data-emotion-css="utzlxm">.css-utzlxm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:end;-webkit-justify-content:flex-end;-ms-flex-pack:end;justify-content:flex-end;width:100%;padding:0 20px 0 25px;}.css-utzlxm .switch{position:relative;display:inline-block;width:50px;height:20px;}.css-utzlxm .switch input{opacity:0;width:0;height:0;}.css-utzlxm .slider{position:absolute;cursor:pointer;top:0;left:0;right:0;bottom:0;background-color:#ccc;-webkit-transition:0.4s;-webkit-transition:0.4s;transition:0.4s;}.css-utzlxm .slider:before{position:absolute;content:'';height:30px;width:30px;left:0px;bottom:4px;top:0;bottom:0;margin:auto 0;-webkit-transition:0.4s;-webkit-transition:0.4s;transition:0.4s;box-shadow:0 0px 15px #2020203d;background:white url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABgAAAAYCAYAAADgdz34AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAAsQAAALEBxi1JjQAAABl0RVh0U29mdHdhcmUAd3d3Lmlua3NjYXBlLm9yZ5vuPBoAAAOfSURBVEiJlZVLaFxVGMd/333NJG2a+ujUJnGSSWljGvPoQ0tBbIooulDoQgSpEou4UOqiLlzpxoVFEIsgaotaaEhBEXVV8EUXgrao0SYxk6ROjCUxfaQvm8fMPfd+LqZJ5k4ySfxW93yP/+Ocw7mwTOhw21odbG8rzuf6N3fl+iqNDm5rXGreKlXwB1oe8vtr0yanF4JY1YeR2lDzbgnHn5JwxvYJjuhwR7wUjixUXBc3Wfsk/lg7sUYkvmXC1vB+qe3K5IZa90s2cxTNWQASa4B4C0AAfO8kOx8pxnMi4OdaEmbmcg9mIoF7NxLfAiIvSLIrAyChjswpsysg3jy7tEEuLeZgbotUsQL/SjdmIoF4SPl2QM7YNce/mO1xG85+p27dy3lp1XMbIPCrfbGsY0kCM7DxWzWXqgCINQIugh4TQSMuYRRAxSnM/Ss7jvglCfy+1gfwx/bMuhWv/lbR/rp4wLZw88qzPYIcBDIscpazkZdhXf2YMLy1DwnIq1Muxv5eMLCp5zPta6qQTb03oRdVDkO7XYpAdLhtrZkcuoKavIp4MxK7ByDrJDtLXr+VhmWy/oE5cECkfPYzpiNP37ZSIE23pLSvyVtAIGR3RTLizn0ay25ZEXjm3vVGL/wWxCrfU22PXH1LMVXR7lzhYu+y4H+1bjWTf45jV6/Bq38+OF/zTYTAEnUjAzozb0bp0H+eW7cUgdT93o274QxeDQChhK9GCELcy5GJILKsDHxzaFkX4qUJp99F5agrzrWIgFy68SPxM/vnMw6y5glg/uYJctBOHn9nOaLCyJ1/ZqeE4WrLldgHUTkGzY1EU+jb/si+t4oPsFSYkX3PWqqnLJGdAmD+SNzU4PqquQ6rDKl4LOIi70T7FN6wA/crSR2bKaypPmmbUfdBCezXEN0DqC1hgwAEg42Hwmwmcjji1UPZ9lIipxB+Ah1FLR90A3AfcGdBz5dOsnOv5Nmxgv7ENQ2uV0RgynYgXmolu1Ic03YQbJPUiXT+xyGEtnPXw1heGG37Bc2e+9/oAq9I6kQaCp5r2Xz2tHqpA4hb8DwrzHSjUz9COL0icEXftJOd7xeQRcMMNT1ObuxzDafcaMVGvFrw6sC6HWTB6DTwkpPs/KTIzSIqhrauM8GNTzHjuwsfwvkpB6w1IHEQVGV1r+vc8aJsPPXDgtaSXgEd2FXtc/V1gslHLabWa5jzEAXsACm/IVbZz8iqw05Dz8lSGP8BjRZeDZkbZsEAAAAASUVORK5CYII=);background-repeat:no-repeat;background-position:center;}.css-utzlxm input:checked + .slider{background:linear-gradient(to right,#fefb72,#f0bb31);}.css-utzlxm input:checked + .slider:before{-webkit-transform:translateX(24px);-ms-transform:translateX(24px);-webkit-transform:translateX(24px);-ms-transform:translateX(24px);transform:translateX(24px);background:white url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABgAAAAYCAYAAADgdz34AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAApgAAAKYB3X3/OAAAABl0RVh0U29mdHdhcmUAd3d3Lmlua3NjYXBlLm9yZ5vuPBoAAANGSURBVEiJndVPbNRVEAfwz9vd/q8tBQtoxSYYDKYmejMGD3DxYloMiRoT22IEDQcPno3xoFclMf6JHrDFyIVEI3g2eiDoRWOMfygqNrSkoeAWCtIu230e3m+77e6KCZO8vH3zZuY7M+/7mxVjVFu7C+vPt7mmh4fi+eEDMUYFVZkdeZU7dhgIzxOj25ULe3fJx6PYamZkDYD4rRDmmgafDIdE3aIJbcrKxkQF4/GtBtuY/43KGVBxOsT/S3YijAomEVBCBe0geNlYfLfBZ3bfJmFlp7u/ONUcYCIMCw6jL1vhFikUURS9Zn88Vn9ZaOJA8DTuA3n0Zjm3ZlDL2VrASpZE8CwaABormAgPC75Cny7cmYE0kwou4Rq4IWeP0fhdc4DjIe+GD0QvIKcbmzOrtl56t9O2gRBYvsKVcyz9ne7nsQgiPhUdtD8uNVYwGRbQK497qu3ZzsYHUuB1EimepTiVKplBGZQM6rI7liFX5/Ur0rPmpYw3ZcEL7fRso3eQQgcCfffT0Z+i9K3GOFMNvh7gWOjDYGpJpuvbkQK1dND/IF1b6Oynf4jW7jU2a3zY6uPQ3whw0/u4S5DYIqsAOjdrkKqutSfbVcncL+ejOoAQsC39VGN9yOiTa8LmXIGOx8h11RxqzzTgeHLOAGKUM4pFFdzMzJYX0n79YiPAP/O0PUSlHTE9cCXdCJ7zVFxZA4DReA4/gKVMd/WvtJcWKf6e6FlapPgHS0UW3uPyN9b58IuxOFU91Ne+E+kL7cb1Oa5O0zPI0kJaa+XaLIszif21q4x2if+1ClLP/iRrUfYNufQTF79P2ceY2lFaZP5HLqaCFaUxmOSsT3RWD42j4mh4RnQEnTZYP+pCLh1Se2uZF0FZdNC0o16Plf8GgMnwOZ5Eot9GiefVmbQiDbtitif52njcUx+q+TSNTgoZQAlzddblJj7ByWah0htc2LvL7L5Nq9r98YhBLSo2481Vfbkh+DtytljWaiy+3QwgxOnhIfl4AmdoGTXw2eUGq8lwWNCDD1WUBC+hYNyLTf9iZ554RAiPG/jyjYKcR7E1wa3sxKkGh/H4Sp3mULNsVyVvTgxTqYIYmRk5oOK0e0/8fEvH25B/AZyRWA6LDlu9AAAAAElFTkSuQmCC);background-repeat:no-repeat;background-position:center;}.css-utzlxm .slider.round{border-radius:34px;}.css-utzlxm .slider.round:before{border-radius:50%;}</style><div class="css-utzlxm e1c69wq20"><label id="switch" class="switch"><input type="checkbox" id="slider" checked=""/><span class="slider round"></span></label></div></li></ul></div></nav><style data-emotion-css="1gvjyvp">.css-1gvjyvp{height:60px;box-shadow:0 3px 6px 0 rgba(0,0,0,0.16);background-color:#f8f8f8;position:relative;display:none;}@media (max-width:767px){.css-1gvjyvp{display:block;}}</style><div class="css-1gvjyvp e1217p0e0"><div class="navBarDefault removePadd"><span class="navBarToggle" role="button" tabindex="0"><span class="iconBar"></span><span class="iconBar"></span><span class="iconBar"></span></span></div></div></div><style data-emotion-css="139q0o8">.css-139q0o8{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;background:#fff;}.css-139q0o8 .sideBarUL li a{color:#3B454E;}.css-139q0o8 .sideBarUL .item > a:hover{background-color:#1ed3c6;color:#fff !important;}@media only screen and (max-width:767px){.css-139q0o8{display:block;}}</style><div class="css-139q0o8 e1eqkayb0"><style data-emotion-css="192n44p">.css-192n44p{width:298px;}</style><div class="hiddenMobile css-192n44p e1eqkayb3"><style data-emotion-css="8uxxw2">.css-8uxxw2{width:100%;height:100vh;overflow:auto;position:fixed;padding-left:0px;position:-webkit-sticky;position:-moz-sticky;position:-webkit-sticky;position:sticky;top:0;padding-right:0;-webkit-box-shadow:-1px 0px 4px 1px rgba(175,158,232,0.4);}@media only screen and (max-width:1023px){.css-8uxxw2{width:100%;height:100vh;}}@media (min-width:767px) and (max-width:1023px){.css-8uxxw2{padding-left:0;}}@media only screen and (max-width:767px){.css-8uxxw2{padding-left:0px;height:auto;}}</style><aside class="css-8uxxw2 e1sbq3r11"><ul class="sideBarUL"><li class="hideFrontLine firstLevel item "><ul><li class=" item "><a href="/cs224n-tensorflow/">Welcome</a></li><li class=" item "><a href="/cs224n-tensorflow/01_word_vectors">1. Word Vectors</a></li><li class=" item "><a href="/cs224n-tensorflow/05_linguistic_structure_dependency_parsing">05. Linguistic Structure: Dependency Parsing</a></li><li class=" item "><a aria-current="page" class="" href="/cs224n-tensorflow/15_natural_language_generation">15. Natural Language Generation</a></li><li class=" item "><a href="/cs224n-tensorflow/introduction">Introduction</a></li><li class=" item "><a href="/cs224n-tensorflow/codeblock">Syntax Highlighting<button aria-label="collapse" class="collapser"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24"><path d="M7.33 24l-2.83-2.829 9.339-9.175-9.339-9.167 2.83-2.829 12.17 11.996z"></path></svg></button></a></li></ul></li></ul></aside></div><style data-emotion-css="zj4uvr">.css-zj4uvr{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;margin:0px 88px;padding-top:3rem;background:#fff;}.css-zj4uvr table tr{background:#fff;}@media only screen and (max-width:1023px){.css-zj4uvr{padding-left:0;margin:0 10px;padding-top:3rem;}}</style><main class="css-zj4uvr e1eqkayb1"><style data-emotion-css="14zj307">@media only screen and (max-width:50rem){.css-14zj307{width:100%;position:relative;}}</style><div class="css-14zj307 e1eqkayb2"><div class="titleWrapper"><style data-emotion-css="1gg19kx">.css-1gg19kx{font-size:32px;line-height:1.5;font-weight:500;border-left:2px solid #1ed3c6;padding:0 16px;-webkit-flex:1;-ms-flex:1;flex:1;margin-top:0;padding-top:0;color:#000;}</style><h1 class="css-1gg19kx e1m7sxnn0">15. Natural Language Generation</h1><style data-emotion-css="qu2iew">.css-qu2iew{padding:1rem 1.5rem;text-align:right;}.css-qu2iew a{font-size:14px;font-weight:500;line-height:1em;-webkit-text-decoration:none;text-decoration:none;color:#555;border:1px solid rgb(211,220,228);cursor:pointer;border-radius:3px;-webkit-transition:all 0.2s ease-out 0s;transition:all 0.2s ease-out 0s;-webkit-text-decoration:none;text-decoration:none;color:rgb(36,42,49);background-color:rgb(255,255,255);box-shadow:rgba(116,129,141,0.1) 0px 1px 1px 0px;height:30px;padding:5px 16px;}.css-qu2iew a:hover{background-color:rgb(245,247,249);}</style><div class="mobileView css-qu2iew e1m7sxnn1"><a href="https://abhishekdutt.github.io/cs224n-tensorflow//15_natural_language_generation.md" class="gitBtn"><img src="data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0idXRmLTgiPz4NCjwhLS0gR2VuZXJhdG9yOiBBZG9iZSBJbGx1c3RyYXRvciAyMi4xLjAsIFNWRyBFeHBvcnQgUGx1Zy1JbiAuIFNWRyBWZXJzaW9uOiA2LjAwIEJ1aWxkIDApICAtLT4NCjxzdmcgdmVyc2lvbj0iMS4yIiBiYXNlUHJvZmlsZT0idGlueSIgaWQ9IkxheWVyXzEiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyIgeG1sbnM6eGxpbms9Imh0dHA6Ly93d3cudzMub3JnLzE5OTkveGxpbmsiDQoJIHg9IjBweCIgeT0iMHB4IiB2aWV3Qm94PSIwIDAgMjM1MCAyMzE0LjgiIHhtbDpzcGFjZT0icHJlc2VydmUiPg0KPHBhdGggZD0iTTExNzUsMEM1MjUuOCwwLDAsNTI1LjgsMCwxMTc1YzAsNTUyLjIsMzc4LjksMTAxMC41LDg5MC4xLDExMzkuN2MtNS45LTE0LjctOC44LTM1LjMtOC44LTU1Ljh2LTE5OS44SDczNC40DQoJYy03OS4zLDAtMTUyLjgtMzUuMi0xODUuMS05OS45Yy0zOC4yLTcwLjUtNDQuMS0xNzkuMi0xNDEtMjQ2LjhjLTI5LjQtMjMuNS01LjktNDcsMjYuNC00NC4xYzYxLjcsMTcuNiwxMTEuNiw1OC44LDE1OC42LDEyMC40DQoJYzQ3LDYxLjcsNjcuNiw3Ni40LDE1NS43LDc2LjRjNDEuMSwwLDEwNS43LTIuOSwxNjQuNS0xMS44YzMyLjMtODIuMyw4OC4xLTE1NS43LDE1NS43LTE5MC45Yy0zOTMuNi00Ny01ODEuNi0yNDAuOS01ODEuNi01MDUuMw0KCWMwLTExNC42LDQ5LjktMjIzLjMsMTMyLjItMzE3LjNjLTI2LjQtOTEuMS02MS43LTI3OS4xLDExLjgtMzUyLjVjMTc2LjMsMCwyODIsMTE0LjYsMzA4LjQsMTQzLjljODguMS0yOS40LDE4NS4xLTQ3LDI4NC45LTQ3DQoJYzEwMi44LDAsMTk2LjgsMTcuNiwyODQuOSw0N2MyNi40LTI5LjQsMTMyLjItMTQzLjksMzA4LjQtMTQzLjljNzAuNSw3MC41LDM4LjIsMjYxLjQsOC44LDM1Mi41YzgyLjMsOTEuMSwxMjkuMywyMDIuNywxMjkuMywzMTcuMw0KCWMwLDI2NC40LTE4NS4xLDQ1OC4zLTU3NS43LDQ5OS40YzEwOC43LDU1LjgsMTg1LjEsMjE0LjQsMTg1LjEsMzMxLjlWMjI1NmMwLDguOC0yLjksMTcuNi0yLjksMjYuNA0KCUMyMDIxLDIxMjMuOCwyMzUwLDE2ODkuMSwyMzUwLDExNzVDMjM1MCw1MjUuOCwxODI0LjIsMCwxMTc1LDBMMTE3NSwweiIvPg0KPC9zdmc+DQo=" alt="Github logo"/> Edit on GitHub</a></div></div><style data-emotion-css="1qktglx">.css-1qktglx{max-width:750px;color:#3B454E;}.css-1qktglx ul,.css-1qktglx ol{-webkit-padding-start:40px;-moz-padding-start:40px;-o-padding-start:40px;margin:24px 0px;padding:0px 0px 0px 2em;}.css-1qktglx ul li,.css-1qktglx ol li{font-size:16px;line-height:1.8;font-weight:400;}.css-1qktglx a{-webkit-transition:color 0.15s;transition:color 0.15s;color:#1000EE;}.css-1qktglx code{border:1px solid #ede7f3;border-radius:4px;padding:2px 6px;font-size:0.9375em;background:#fff;}@media (max-width:767px){.css-1qktglx{padding:0 15px;}}</style><div class="css-1qktglx e1m7sxnn2"><h2 class="heading2" id="plan:">Plan:</h2><ol><li>Recap what we already know about NLG</li><li>More on decoding algorithms</li><li>NLG tasks and neural approaches to them</li><li>BLG evaluation: a tricky situation</li><li>Concluding thought on NLG research, current trends and the future</li></ol><h3 class="heading3" id="whatisnlg:">What is NLG:</h3><p class="paragraph">NLG refers to any setting in which we generate new text.</p><p class="paragraph">NLG is a subcomponent of:</p><ul><li>Machine Translation</li><li>(Abstractive) Summarizaiton</li><li>Dialogue (chit-chat and task-based)</li><li>Creative writing: Storytelling, poetry-generation</li><li>Freeform Question Answering (i.e. anser is generated, not extracted from text or knowledge base)</li><li>Image captioning</li><li>etc.</li></ul><h2 class="heading2" id="1.recapwhatwealreadyknowaboutnlg">1. Recap what we already know about NLG</h2><ul><li>Language Modeling: the task of <strong>predicting the next word</strong>, given the words so far:
P(yt|y1,...,yt-1)</li><li>A system that produces this probability distribution is called Language Model</li><li>Contitional Language Modeling: the task of predicting the next word, given the words so far, <strong>and also some other input x</strong>
P(yt|y1,...,yt-1,x)</li><li>Examples of Conditional Language modeling tasks:<ul><li>Machine Translation (x=source sentence, y=trget sentence)</li><li>Summarization (x=input text, y=summarized text)</li><li>Dialogue (x=dialogue history, y=next utterance)</li><li>etc.</li></ul></li></ul><h3 class="heading3" id="recap:traininga(conditional)rnn-lm:">Recap: training a (conditional) RNN-LM:</h3><p class="paragraph"><span class="gatsby-resp-image-wrapper" style="position:relative;display:block;margin-left:auto;margin-right:auto;max-width:1035px">
      <a href="/cs224n-tensorflow/static/8e62c1e1ce531db0d16f543189fdd7db/b0eb8/15_RNN.png" target="_blank" rel="noopener noreferrer">
    <span class="gatsby-resp-image-background-image" style="padding-bottom:75%;position:relative;bottom:0;left:0;background-image:url(&#x27;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAPCAYAAADkmO9VAAAACXBIWXMAABcSAAAXEgFnn9JSAAACz0lEQVQ4y21U247bNhD1/39KHwIELbZA0AZBEaANstl643WyzdqWLdu6i6KuvIonI3JzeSiB4xkOyZnD4ZFXxgJsAAYJTArgU4DQIdYJh6JzaEaHmvblrfOoegdpQMPBuYBlrAbp8PfO4Z+9w/bq8P7g8PaLw23ksDk7vIuAD2dgmwCbi8MD2fsr8CmFL/LzWJKulh9lHAZiMimqqh2xo7kMDHipYBhRdXM4JQxcI4A5zHVnIEoBq2xgiIWqpxuqzdYiS1PkWepjYz6ARQ36dsAkJKqYodoxdE0PKRWqYwUeccx6fk74P6NpORhvvM97g6ySyIhlwTXOhUBRKyQ1Je80jsmIutE/rmyl9ZQ9KgFJBzUd1C1tMjOa3uLKDC6VQcIsolwhayzi0iDnFrtUe/s94UJ1zCZMhcRUSgiqPhbBOirGuEFaa1wrSsSIUSaRE6O4UChpbZ8Isvr5VejKKk1D78QIp6jZavJwcvTxepixvUj8l2iP7Zl8YvV41Xgie3+S2GXaZ8sFx2r89BnzOODu5g7v/njE5s0W61drrF8/4FIDt4cOLz7E+PU+we+bDC9JM7+tr7j5mOGGYr+Qpu5OOWYYPLZnrGQcw2qNOrqCXQq01xxNnKJLSsx0hV4IZG2NjNcoe46kKVG0jMTeeHupc/CxhSVZHYaUdEgysaQpO1sYaygJ6VBJDGO4spQCQ9dDK+WhqMBiJ1pfJKYkPaIKPdSzCbKZKeE0TRjHydu2bZFSbxVtZE3j/X4Y0Pe9t5zWGWMQlLyjWMO5z/EsbKAsCpzjI6LDHof9DvHpiNMxokO1b3bftdg9ffGx/e4JcXzCadlDMFp5fPswVoszCEv9mEmoFg29KuuDX5Nlgwvon+c+Nvv5srcT8H8aVRc+15U19CCk+Iw7EvCMf4/2O+4ii01s8fFksab57SH494S/Phu83hr8+aBxyAOhpfBX4Zh5Q4w4DzwAAAAASUVORK5CYII=&#x27;);background-size:cover;display:block"></span>
  <img class="gatsby-resp-image-image" alt="Recap: RNN-LM" title="Recap: RNN-LM" src="/cs224n-tensorflow/static/8e62c1e1ce531db0d16f543189fdd7db/bcbcb/15_RNN.png" srcSet="/cs224n-tensorflow/static/8e62c1e1ce531db0d16f543189fdd7db/8472d/15_RNN.png 259w,/cs224n-tensorflow/static/8e62c1e1ce531db0d16f543189fdd7db/9eb08/15_RNN.png 518w,/cs224n-tensorflow/static/8e62c1e1ce531db0d16f543189fdd7db/bcbcb/15_RNN.png 1035w,/cs224n-tensorflow/static/8e62c1e1ce531db0d16f543189fdd7db/b0eb8/15_RNN.png 1500w" sizes="(max-width: 1035px) 100vw, 1035px" style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0" loading="lazy"/>
  </a>
    </span></p><h3 class="heading3" id="recap:decodingalgorithms">Recap: decoding algorithms</h3><p class="paragraph">Question: Once you’ve trained your (conditional) language model, how do you use it to generate text?
Answer: A decoding algorithm is an algorithm you use to generate text from your language model.</p><p class="paragraph">We’ve learnt about two decoding algorithms: </p><ul><li>Greedy decoding</li><li>Beam search</li></ul><h3 class="heading3" id="onethingnotdiscussedearlieraboutbeamsearch:">One thing not discussed earlier about Beam Search:</h3><p class="paragraph"><span class="gatsby-resp-image-wrapper" style="position:relative;display:block;margin-left:auto;margin-right:auto;max-width:1035px">
      <a href="/cs224n-tensorflow/static/2ef81f4612d26bcdc203d43b7482b3ca/b0eb8/15_beam_size_k.png" target="_blank" rel="noopener noreferrer">
    <span class="gatsby-resp-image-background-image" style="padding-bottom:75%;position:relative;bottom:0;left:0;background-image:url(&#x27;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAPCAYAAADkmO9VAAAACXBIWXMAABcSAAAXEgFnn9JSAAACk0lEQVQ4y21U2ZKbMBD0//9UHpLKS7Z2fXIfxmDMjfGJBajTwvauNxVVtTUaxq1Rt2DS9RJpI1Gdgfossb9IlCeJ4ihxuDJ/umN/vkPFKv9cN6xXQ8r7PGk7YBoCeiwRFICdAQ6hxcCmAnzm5hGw2N6h7QA3v8Mh0sNIhwcfJugFpBA4CHDHFoemRFllaJoCeZ6gKNMxl5cZsiJFxWcqX3JdVTmG7va9Q8gBp3bAblMj1WzsVhqi6Qw700K0WCAmdpaNcDZDRGzVc2Lz/oHEtiG67jvho1PgcoAseNbrFTjwHJcLcKawxyPQXu+xgsqzRrJGqviF7N5hJ3C9CKQnHrkFojhGkuVIknREsN4g5RxvdyPUOgoj9A+OJ9nLkSVaIeFFJVxvg+V8ATfwoBc+rDKEngdw6xh6GYzxNLVhcHZchxvEn2RfhBwD4y0fzmYf8H0fju8hCH00awe1raPxbexdC7VronIMNBsfx32Nizr6g+yJibJcte+tQ5imgfV6DYtiO66HNNhA0JBW0yG4FrYD4floaUoXRfjfmDxbFRTYc13M5nMkloWM7mbLJSpDR22aKOlw/ucPio93VCq/WiFgnUHYbCAMQ/R9/0U4DAM19KDpOgzCMgyYmgaDMBlrJDFIsuKGKnZJkuxoFE3M8xwdr8945Cdh37Zw2Ykimb69YTqdUtMZpsSKRAZJVfdLxhprPOqcpim139KcLS95+WXK6BQ7vGUZLtTwpnZNEiT8Q0StiqL4x005GtnxR30Lun74vEaTV8ufY1BXiR0r3G63EVc6qtaCr6laD4KXWpz52p4f8wmSr/FEFajC18tZ1zWW1ElXeiotlRSEipVxtuPhsH5DH/6GCH4RPyH8HxhOKf4Cnj1tTnko2BoAAAAASUVORK5CYII=&#x27;);background-size:cover;display:block"></span>
  <img class="gatsby-resp-image-image" alt="Effect of changing the Beam size K" title="Effect of changing the Beam size K" src="/cs224n-tensorflow/static/2ef81f4612d26bcdc203d43b7482b3ca/bcbcb/15_beam_size_k.png" srcSet="/cs224n-tensorflow/static/2ef81f4612d26bcdc203d43b7482b3ca/8472d/15_beam_size_k.png 259w,/cs224n-tensorflow/static/2ef81f4612d26bcdc203d43b7482b3ca/9eb08/15_beam_size_k.png 518w,/cs224n-tensorflow/static/2ef81f4612d26bcdc203d43b7482b3ca/bcbcb/15_beam_size_k.png 1035w,/cs224n-tensorflow/static/2ef81f4612d26bcdc203d43b7482b3ca/b0eb8/15_beam_size_k.png 1500w" sizes="(max-width: 1035px) 100vw, 1035px" style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0" loading="lazy"/>
  </a>
    </span></p><h3 class="heading3" id="anotherfamilyofdecodingalgorithms:samplingbaseddecoding">Another family of decoding algorithms: Sampling Based Decoding</h3><ul><li>Pure sampling</li><li>Top-n sampling</li></ul><p class="paragraph"><em>Both of these are more efficient than Beam serach, no more multiple hypotheses</em></p><h3 class="heading3" id="softmaxtemperature">Softmax temperature</h3><p class="paragraph"><em>Softmax temperature is not a decoding algorithm.</em>
<em>It’s a technique you can apply at test time, in conjunction with a decoding algorithm (such as beam search or sampling)</em></p><h3 class="heading3" id="decodingalgorithms:insummary">Decoding algorithms: in summary</h3><ul><li>Greedy decoding</li><li>Beam search</li><li>Sampling methods</li><li>Softmax temperature</li></ul><h2 class="heading2" id="2.nlgtasksandneuralapproachestothem">2. NLG tasks and neural approaches to them</h2><h3 class="heading3" id="2.1.1.summarization:taskdefinition">2.1.1. Summarization: task definition</h3><p class="paragraph">Task: given input text x, write a summary y which is shorter and contains the main information of x.
Summarization can be </p><ul><li>Single-document </li><li>Multi-document</li></ul><p class="paragraph">Training data sources:</p><ul><li>Gigaword</li><li>LCSTS (Chinese microblogging)</li><li>NYT, CNN/DailyMail</li><li>Wikihow</li></ul><p class="paragraph"><strong>Sentence simplification:</strong> is a different but related task: rewrite the source text in a simpler (sometimes shorter) way</p><ul><li>Simple Wikipedia: standard Wikipedia sentence → simple version</li><li>Newsela: news article → version written for children</li></ul><h3 class="heading3" id="2.1.2.summarization:howtodoit">2.1.2. Summarization: How to do it</h3><p class="paragraph">Two main strategies:</p><ul><li><strong>Extractive summarization:</strong> Select parts (typically sentences) of the original text to form a summary.</li><li><strong>Abstractive summarization:</strong> Generate new text using natural language generation techniques.</li></ul><h4 class="heading4" id="explanationaboutpre-neuralwayofsummarization:">Explanation about pre-neural way of summarization:</h4><p class="paragraph">They were mostly extractive.
Like pre-neural MT, they typically had a pipeline:</p><ul><li><p class="paragraph">Content selection:</p><ul><li>Sentence scoring functions: can be based on:<ul><li>Presence of topic keywords,computed via e.g.tf-idf</li><li>Features such as where the sentence appears in the document</li></ul></li><li>Graph-based algorithms: view the document as a set of sentences (nodes), with edges between each sentence pair<ul><li>Edge weight is proportional to sentence similarity</li><li>Use graph algorithms to identify sentences which are central in the graph</li></ul></li></ul></li><li><p class="paragraph">Information ordering</p></li><li><p class="paragraph">Sentence realization</p></li></ul><h3 class="heading3" id="2.1.3.howtoevaluatesummarization:">2.1.3. How to evaluate Summarization:</h3><p class="paragraph"><strong>ROUGE:</strong> Recall-Oriented Understudy for Gisting Evaluation
<em>There is now a convenient Python implementation of ROUGE!</em></p><h3 class="heading3" id="2.1.4.neuralsummarization(2015-present)">2.1.4. Neural summarization (2015 - present)</h3><p class="paragraph">2015: Rush et al. publish the first seq2seq summarization paper
Since 2015, there have been lots more developments!
Copy mechanisms use attention to enable a seq2seq system to easily copy words and phrases from the input to the output</p><ul><li>Clearly this is very useful for summarization</li><li>Allowing both copying and generating gives us a <strong>hybrid extractive/abstractive approach</strong>
There are several papers proposing copy mechanism variants:</li></ul><p class="paragraph">Big problem with copying mechanisms: </p><ul><li>They copy too much!</li><li>Mostly long phrases,sometimes even whole sentences</li><li>What should be an abstractive system collapses to a mostly extractive system.
Another problem:</li><li>They’re bad at overall content selection, especially if the input document is long</li><li>No overall strategy for selecting content</li></ul><h3 class="heading3" id="2.1.5.onesolution:bottom-upsummarization:">2.1.5. One solution: bottom-up summarization:</h3><p class="paragraph">Simple but effective!</p><ul><li>Content selection stage: Use a neural sequence-tagging model to tag words as include or don’t-include</li><li>Bottom-up attention stage: The seq2seq+attention system can’t attend to words tagged don’t-include (apply a mask)</li></ul><p class="paragraph">In 2017 Paulus et al published a “deep reinforced” summarization model</p><ul><li>A Deep Reinforced Model for Abstractive Summarization, Paulus et al, 2017 <a href="https://arxiv.org/pdf/1705.04304.pdf" target="_blank" rel="noopener noreferrer">https://arxiv.org/pdf/1705.04304.pdf</a></li><li>Blog post: <a href="https://www.salesforce.com/products/einstein/ai-research/tl-dr-reinforced-model-abstractive-summarization/" target="_blank" rel="noopener noreferrer">https://www.salesforce.com/products/einstein/ai-research/tl-dr-reinforced-model-abstractive-summarization/</a></li></ul><h1 class="heading1" id="thisbeginningtolooklikeapapertour">This beginning to look like a paper tour</h1><h3 class="heading3" id="2.2.1.dialogue">2.2.1. Dialogue</h3><p class="paragraph">“Dialogue” encompasses a large variety of settings:</p><ul><li>Task-oriented dialogue<ul><li>Assistive (e.g. customer service, giving recommendations, question answering, helping user accomplish a task like buying or booking something)</li><li>Co-operative (two agents solve a task together through dialogue)</li><li>Adversarial (two agents compete in a task through dialogue)</li></ul></li><li>Social dialogue<ul><li>Chit-chat (for fun or company)</li><li>Therapy / mental wellbeing</li></ul></li></ul><h3 class="heading3" id="2.2.2.seq2seq-baseddialogue">2.2.2. Seq2seq-based dialogue</h3><p class="paragraph">• However, it quickly became apparent that a naïve application of standard seq2seq+attention methods has serious pervasive deficiencies for (chitchat) dialogue:
• Genericness / boring responses
• Irrelevant responses (not sufficiently related to context) • Repetition
• Lack of context (not remembering conversation history) • Lack of consistent persona</p><h3 class="heading3" id="2.2.3.negotiationdialogue">2.2.3. Negotiation dialogue</h3><p class="paragraph">Papers:</p><ul><li>A Neural Conversational Model, Vinyals et al, 2015 <a href="https://arxiv.org/pdf/1506.05869.pdf" target="_blank" rel="noopener noreferrer">https://arxiv.org/pdf/1506.05869.pdf</a></li><li>Neural Responding Machine for Short-Text Conversation, Shang et al, 2015 <a href="https://www.aclweb.org/anthology/P15-1152" target="_blank" rel="noopener noreferrer">https://www.aclweb.org/anthology/P15-1152</a></li><li>A Diversity-Promoting Objective Function for Neural Conversation Models, Li et al, 2016 <a href="https://arxiv.org/pdf/1510.03055.pdf" target="_blank" rel="noopener noreferrer">https://arxiv.org/pdf/1510.03055.pdf</a></li><li>Why are Sequence-to-Sequence Models So Dull?, Jiang et al, 2018 <a href="https://staff.fnwi.uva.nl/m.derijke/wp-content/papercite-data/pdf/jiang-why-2018.pdf" target="_blank" rel="noopener noreferrer">https://staff.fnwi.uva.nl/m.derijke/wp-content/papercite-data/pdf/jiang-why-2018.pdf</a></li><li>A Persona-Based Neural Conversation Model, Li et al 2016, <a href="https://arxiv.org/pdf/1603.06155.pdf" target="_blank" rel="noopener noreferrer">https://arxiv.org/pdf/1603.06155.pdf</a> </li><li>Personalizing Dialogue Agents: I have a dog, do you have pets too?, Zhang et al, 2018 <a href="https://arxiv.org/pdf/1801.07243.pdf" target="_blank" rel="noopener noreferrer">https://arxiv.org/pdf/1801.07243.pdf</a></li><li>Deal or No Deal? End-to-End Learning for Negotiation Dialogues, Lewis et al, 2017 <a href="https://arxiv.org/pdf/1706.05125.pdf" target="_blank" rel="noopener noreferrer">https://arxiv.org/pdf/1706.05125.pdf</a></li><li>Hierarchical Text Generation and Planning for Strategic Dialogue, Yarats et al, 2018 <a href="https://arxiv.org/pdf/1712.05846.pdf" target="_blank" rel="noopener noreferrer">https://arxiv.org/pdf/1712.05846.pdf</a></li></ul><h3 class="heading3" id="2.3.1.storytelling">2.3.1. Storytelling</h3><p class="paragraph">Most neural storytelling work uses some kind of prompt</p><ul><li><p class="paragraph">Generate a story-like paragraph given an image</p></li><li><p class="paragraph">Generate a story given a brief writing prompt</p></li><li><p class="paragraph">Generate the next sentence of a story, given the story so far (story continuation)</p><ul><li>This is different to the previous two, because we are not concerned with the system’s performance over several generated sentences</li></ul></li><li><p class="paragraph">Neural storytelling is taking off!</p><ul><li>The first Storytelling Workshop was held in 2018</li><li>It held a competition (generate a story to accompany a sequence of 5 images)</li></ul></li></ul><h3 class="heading3" id="2.4.1.poetrygeneration:hafez">2.4.1. Poetry generation: Hafez</h3><p class="paragraph"><strong>Hafez:</strong> a poetry generation system by Ghazvininejad et al
<strong>Main idea:</strong> Use a Finite State Acceptor (FSA) to define all possible sequences that obey the desired rhythm constraints. Then use the FSA to constrain the output of a RNN-LM.</p><h3 class="heading3" id="2.5.1.non-autoregressivegenerationfornmt">2.5.1. Non-autoregressive generation for NMT</h3><h1 class="heading1" id="thoughtsaboutthislecture">Thoughts about this lecture</h1><p class="paragraph">Actually This lecture does not provide a lot of practival things that can be utilized directly in your day job.
For this reasons, this writeup will be fairly superfecial and not comprehensive.</p><p class="paragraph">However it does provide very useful NLG task decription, current approaches and thier problems and papers/resources relevant these tasks. This writeup just aims to bring all this knowledge together in one place.
This is intented to serve as a starting point to anyone working on these problems.</p><h2 class="heading2" id="3.nlgevaluation">3. NLG evaluation</h2><p class="paragraph">How do we evaluate and compare the performance one NLG system to another?</p><p class="paragraph">Word overlap based metrics (BLEU, ROUGE, METEOR, F1, etc.) are not ideal for machine translation.</p><p class="paragraph">What about perplexity?
Word embedding based metrics?</p><p class="paragraph">We have no automatic metrics to adequately capture overall quality (i.e. a proxy for human quality judgment).
But we can define more focused automatic metrics to capture particular aspects of generated text:
• Fluency (compute probability w.r.t. well-trained LM)
• Correct style (prob w.r.t. LM trained on target corpus)
• Diversity (rare word usage, uniqueness of n-grams)
• Relevance to input (semantic similarity measures)
• Simple things like length and repetition
• Task-specific metrics e.g. compression rate for summarization
Though these don’t measure overall quality, they can help us track some important qualities that we care about.</p><p class="paragraph">Human evaluation
• Human judgments are regarded as the gold standard
• Of course, we know that human eval is slow and expensive
• ...but are those the only problems?
• Supposing you do have access to human evaluation:
Does human evaluation solve all of your problems?
• No!</p><h3 class="heading3" id="3.x.xdetailedhumanevalofcontrollablechatbots">3.x.x Detailed human eval of controllable chatbots</h3><p class="paragraph">Ultimately, we designed a detailed human evaluation system that separates out the important factors that contribute to overall chatbot quality:
What makes a good conversation? How controllable attributes affect human judgments, See et al, 2019 <a href="https://arxiv.org/pdf/1902.08654.pdf" target="_blank" rel="noopener noreferrer">https://arxiv.org/pdf/1902.08654.pdf</a></p><h3 class="heading3" id="possiblenewavenuesfornlgeval?">Possible new avenues for NLG eval?</h3><h2 class="heading2" id="4.thoughtsonnlgresearch,currenttrends,andthefuture">4. Thoughts on NLG research, current trends, and the future</h2><h3 class="heading3" id="4.1.excitingcurrenttrendsinnlg">4.1. Exciting current trends in NLG</h3><ul><li>Incorporating discrete latent variables into NLG<ul><li>May help with modeling structure in tasks that really need it, like storytelling, task-oriented dialogue, etc</li></ul></li><li>Alternatives to strict left-to-right generation<ul><li>Parallel generation, iterative refinement, top-down generation for longer pieces of text</li></ul></li><li>Alternative to maximum likelihood training with teacher forcing<ul><li>More holistic sentence-level (rather than word-level)
objectives</li></ul></li></ul><p class="paragraph">Neural NLG community is rapidly maturing</p><ul><li>During the early years of NLP + Deep Learning, community was mostly transferring successful NMT methods to NLG tasks.</li><li>Now, increasingly more inventive NLG techniques emerging, specific to non-NMT generation settings.</li><li>Increasingly more (neural) NLG workshops and competitions, especially focusing on open-ended NLG:<ul><li>NeuralGen workshop</li><li>Storytelling workshop</li><li>Alexa challenge</li><li>ConvAI2 NeurIPS challenge</li></ul></li><li>These are particularly useful to organize the community, increase reproducibility, standardize eval, etc.</li><li>The biggest roadblock for progress is eval</li></ul><h3 class="heading3" id="8thingsi’velearntfromworkinginnlg">8 things I’ve learnt from working in NLG</h3><ol><li>The more open-ended the task, the harder everything becomes. <em>Constraints are sometimes welcome!</em></li><li>Aiming for a specific improvement can be more manageable than aiming to improve overall generation quality.</li><li>If you’re using a LM for NLG: improving the LM (i.e. perplexity) will most likely improve generation quality. <em>...but it&#x27;s not the only way to improve generation quality.</em></li><li>Look at your output, a lot</li><li>You need an automatic metric, even if it&#x27;s imperfect. <em>You probably need several automatic metrics.</em></li><li>If you do human eval, make the questions as focused as possible.</li><li>Reproducibility is a huge problem in today&#x27;s NLP + Deep Learning, and a huger problem in NLG. <em>Please, publicly release all your generated output along with your paper!</em></li><li>Working in NLG can be very frustrating. But also very funny...</li></ol></div><div class="addPaddTopBottom"><style data-emotion-css="qlf7aj">.css-qlf7aj{margin:0px;padding:0px;width:auto;display:grid;grid-template-rows:auto;-webkit-column-gap:24px;column-gap:24px;grid-template-columns:calc(50% - 8px) calc(50% - 8px);}.css-qlf7aj .previousBtn{cursor:pointer;-moz-box-align:center;-moz-box-direction:normal;-moz-box-orient:horizontal;margin:0px;padding:0px;position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;place-self:stretch;border-radius:3px;border:1px solid rgb(230,236,241);-webkit-transition:border 200ms ease 0s;transition:border 200ms ease 0s;box-shadow:rgba(116,129,141,0.1) 0px 3px 8px 0px;-webkit-text-decoration:none;text-decoration:none;background-color:#fff;color:#3B454E;}.css-qlf7aj .nextBtn{cursor:pointer;-moz-box-align:center;-moz-box-direction:normal;-moz-box-orient:horizontal;margin:0px;padding:0px;position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;place-self:stretch;border-radius:3px;border:1px solid rgb(230,236,241);-webkit-transition:border 200ms ease 0s;transition:border 200ms ease 0s;box-shadow:rgba(116,129,141,0.1) 0px 3px 8px 0px;-webkit-text-decoration:none;text-decoration:none;background-color:#fff;color:#3B454E;}.css-qlf7aj .nextBtn:hover,.css-qlf7aj .previousBtn:hover{-webkit-text-decoration:none;text-decoration:none;border:1px solid #1ed3c6;}.css-qlf7aj .nextBtn:hover .rightArrow,.css-qlf7aj .previousBtn:hover .leftArrow{color:#1ed3c6;}.css-qlf7aj .leftArrow{display:block;margin:0px;color:rgb(157,170,182);-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;font-size:24px;-webkit-transition:color 200ms ease 0s;transition:color 200ms ease 0s;padding:16px;padding-right:16px;}.css-qlf7aj .rightArrow{-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;font-size:24px;-webkit-transition:color 200ms ease 0s;transition:color 200ms ease 0s;padding:16px;padding-left:16px;display:block;margin:0px;color:rgb(157,170,182);}.css-qlf7aj .nextPreviousTitle{display:block;margin:0px;padding:0px;-webkit-transition:color 200ms ease 0s;transition:color 200ms ease 0s;}.css-qlf7aj .nextPreviousTitle span{font-size:16px;line-height:1.5;font-weight:500;}@media (max-width:767px){.css-qlf7aj{display:block;padding:0 15px;}.css-qlf7aj .previousBtn{margin-bottom:20px;}}</style><div class="css-qlf7aj ex6i9xe0"><a class="previousBtn" href="/cs224n-tensorflow/05_linguistic_structure_dependency_parsing"><div class="leftArrow"><svg preserveAspectRatio="xMidYMid meet" height="1em" width="1em" fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" stroke="currentColor" class="_13gjrqj"><g><line x1="19" y1="12" x2="5" y2="12"></line><polyline points="12 19 5 12 12 5"></polyline></g></svg></div><div class="preRightWrapper"><div class="smallContent"><span>Previous</span></div><div class="nextPreviousTitle"><span>05. Linguistic Structure: Dependency Parsing</span></div></div></a><a class="nextBtn" href="/cs224n-tensorflow/introduction"><div class="nextRightWrapper"><div class="smallContent"><span>Next</span></div><div class="nextPreviousTitle"><span>Introduction</span></div></div><div class="rightArrow"><svg preserveAspectRatio="xMidYMid meet" height="1em" width="1em" fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" stroke="currentColor" class="_13gjrqj"><g><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></g></svg></div></a></div></div></div></main><style data-emotion-css="gqp3x7">.css-gqp3x7{width:224px;}</style><div class="hiddenMobile css-gqp3x7 e1eqkayb4"><style data-emotion-css="1dq6tsi">.css-1dq6tsi{width:100%;border-right:1px solid #ede7f3;height:100vh;overflow:auto;position:fixed;padding-left:24px;position:-webkit-sticky;position:-moz-sticky;position:-webkit-sticky;position:sticky;top:0;background:#fff;}.css-1dq6tsi .rightSideTitle{font-size:10px;line-height:1;font-weight:700;text-transform:uppercase;-webkit-letter-spacing:1.2px;-moz-letter-spacing:1.2px;-ms-letter-spacing:1.2px;letter-spacing:1.2px;padding:7px 24px 7px 16px;border-left:1px solid #e6ecf1;border-left-color:rgb(230,236,241);color:#3B454E;}.css-1dq6tsi .rightSideBarUL{margin-top:32px;}.css-1dq6tsi .rightSideBarUL li{list-style-type:none;border-left:1px solid #e6ecf1;border-left-color:rgb(230,236,241);}.css-1dq6tsi .rightSideBarUL li a{font-size:12px;font-weight:500;line-height:1.5;padding:7px 24px 7px 16px;color:#3B454E;}@media only screen and (max-width:50rem){.css-1dq6tsi{width:100%;position:relative;}}</style><aside class="css-1dq6tsi e1y52jk20"><ul class="rightSideBarUL"><li class="rightSideTitle">CONTENTS</li><style data-emotion-css="10m2n0t">.css-10m2n0t{list-style:none;}.css-10m2n0t a{color:#5c6975;-webkit-text-decoration:none;text-decoration:none;font-weight:400;padding:0.45rem 0 0.45rem 3rem;display:block;position:relative;}.css-10m2n0t a:hover{color:#1ed3c6 !important;}.css-10m2n0t a svg{float:right;margin-right:1rem;}</style><li class="css-10m2n0t e1y52jk21"><a href="##" to="##"></a></li><li class="css-10m2n0t e1y52jk21"><a href="#thisbeginningtolooklikeapapertour" to="#thisbeginningtolooklikeapapertour">This beginning to look like a paper tour</a></li><li class="css-10m2n0t e1y52jk21"><a href="#thoughtsaboutthislecture" to="#thoughtsaboutthislecture">Thoughts about this lecture</a></li></ul></aside></div></div></div></div></div><script id="gatsby-script-loader">/*<![CDATA[*/window.pagePath="/15_natural_language_generation";/*]]>*/</script><script id="gatsby-chunk-mapping">/*<![CDATA[*/window.___chunkMapping={"app":["/app-427e7e4f4c0d4bff0465.js"],"component---src-templates-docs-js":[]};/*]]>*/</script><script src="/cs224n-tensorflow/app-427e7e4f4c0d4bff0465.js" async=""></script><script src="/cs224n-tensorflow/commons-926e13980b7ff3c9526c.js" async=""></script><script src="/cs224n-tensorflow/webpack-runtime-2f446e3feebf622e1bcb.js" async=""></script><script defer="">
            function navBarClose() {
              document.getElementById("navbar").classList.toggle("responsive");
            }
            document.addEventListener('click',function(e){
              if(e.target && e.target.tagName.toLowerCase() === 'a'){
                navBarClose();
              }
           });
            </script></body></html>